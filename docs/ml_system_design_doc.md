# ML System Design Doc - RU  
## Дизайн ML системы — Оценка операторов по транскриптам — MVP v1.0

---

### 1. Цели и предпосылки

#### 1.1. Зачем идем в разработку продукта?

- **Бизнес-цель:** увеличить долю оценённых обращений операторов с <1% до не менее 10%.
- **Ожидаемое улучшение:** снижение зависимости от ручной оценки, повышение масштабируемости и единообразия оценок.
- **Критерий успеха итерации:** ≥80% совпадения с оценкой QA-специалистов на тестовой выборке.

#### 1.2. Бизнес-требования и ограничения

- **Краткое описание БТ:** автоматическая оценка звонков операторов клиентского сервиса по текстовым транскрипциям с использованием ML.
- **Ограничения:**
  - Используются только обезличенные данные.
  - Использование инфраструктуры локального исполнения (без внешних API).
- **Ожидания от итерации:** batch-оценка ≥10% ежедневных транскрипций.
- **Интеграция в бизнес-процесс:** результаты передаются в систему мониторинга качества и используются для KPI/обратной связи.
- **Критерий успешного пилота:** ≥80% согласованности оценок с QA, устойчивость обработки заданного объема выборки.

#### 1.3. Скоуп

- **Входит:**
  - Batch-инференс.
  - Модель оценки по критериям (0–2).
  - Формирование отчёта (оценки + объяснения).
- **Не входит:**
  - Real-time инференс.
  - Интеграция с KPI-системами на уровне продакшена.
  - Полный UI.
- **Качество решения:** воспроизводимый код, изолированное окружение через Poetry, единый пайплайн подготовки данных и инференса.
- **Планируемый технический долг:** оптимизация latency, переход к real-time.

#### 1.4. Предпосылки

- Исходные данные — транскрипты, полученные из STT.
- Доступна историческая экспертная разметка (QA).
- Объём данных ~1000 звонков в сутки.
- ПД скрыты на уровне транскрибации.

---

### 2. Методология

#### 2.1. Постановка задачи

- Тип задачи: автоматизированная многокритериальная оценка диалогов (multi-label classification) с диапазоном значений `0–2` по каждому критерию + текстовое пояснение.

#### 2.2. Блок-схема решения (MVP)

```
[Транскрипты] → [Предобработка] → [LLM scoring (GPT-OSS 20B via vLLM)] 
        → [Стандартизация оценок] → [Сохранение результатов] → [Сравнение с QA]
```

#### 2.3. Этапы

**Этап 1 — Подготовка данных**

| Данные | Источник | Роли | Проверка качества |
|--------|----------|------|-------------------|
| Транскрипты звонков | STT система | DS/DE | + |
| Разметка QA | Внутренний репозиторий QA | DS/DE | + |
| Метаданные звонков | Внутренние системы | DS/DE | частично |

**Результат этапа:** витрина `<transcript, qa_score, metadata>`.

---

**Этап 2 — Бейзлайн**

- Подход: zero/few-shot prompting.
- Модель: GPT-OSS 20b (vLLM).
- Метрики: Cohen’s Kappa, Accuracy per criterion.
- Ожидаемый результат: kappa ≥0.6.

---

**Этап 3 — MVP модель**

- Подход: few-shot prompting + fine-tuning на исторической разметке.
- Выборка: train/test на исторических данных.
- Метрики качества: Cohen’s Kappa ≥0.8, стабильность оценок по критериям.
- Риски: несбалансированность классов, drift данных.

---

**Этап 4 — Инференс**

- Режим: batch ежедневно.
- Выход модели: оценки по критериям + короткое текстовое объяснение.
- Формат выгрузки: JSON + табличная форма для аналитики.

---

**Этап 5 — Валидация**

- Проверка выборки QA специалистами для подтверждения согласованности оценок.

---

### 3. Подготовка пилота

#### 3.1. Способ оценки

- Сравнение модельных оценок с ручными оценками QA на отложенной выборке (A/B).
- Контрольная доля: ~20% модельно-оценённых диалогов.

#### 3.2. Условия успешности

- Cohen’s Kappa ≥0.8.
- Обработка ≥10% суточных транскриптов.

#### 3.3. Ограничения вычислений

- Инференс self-hosted через vLLM.
- Точная стоимость вычислений будет уточнена после расчёта медианного времени инференса на бейзлайне.

#### 3.4. Блок схема решения

Транскрипт → Предобработка → LLM-оценка → Оценки по критериям (0–2) + Пояснение → Сохранение результата → Отчет для QA/бизнеса

---



## 2. Этапы решения задачи 

Данный раздел описывает поэтапное решение задачи автоматической оценки операторов по транскриптам звонков с точки зрения Data Scientist. Описание основано на результатах предварительного анализа данных (EDA) и отражает специфику текущей задачи, доступных данных и бизнес-целей.

---

### Этап 1. Подготовка и валидация данных

#### Данные и сущности

Основной объект анализа — звонок, представленный в виде одного текстового транскрипта (на русском языке), полученного от STT-системы.  
Средняя длина транскрипта составляет ~2000 символов (~315 слов), что укладывается в контекстное окно используемой LLM.

Используется историческая QA-разметка по 11 критериям качества, каждый из которых оценивается по шкале `0 / 1 / 2`. Пропуски в разметке отсутствуют. Распределение классов существенно несбалансировано с доминированием значения `2`.

**Логическая структура данных:**

- Таблица звонков (features):
  - call_id  
  - transcript_text  
  - checklist_type  
  - служебные метаданные звонка (в текущей итерации не используются как признаки)

- Таблица целевых переменных:
  - call_id  
  - criterion_name  
  - qa_score ∈ {0,1,2}

- Таблица результатов модели:
  - call_id  
  - criterion_name  
  - model_score ∈ {0,1,2}  
  - model_explanation  

#### Источники данных

| Название данных | Источник | Ресурсы | Качество |
|----------------|----------|---------|----------|
| Транскрипты звонков | STT-система | DE / DS | + |
| QA-разметка | Внутренний репозиторий QA | DS | + |
| Метаданные звонков | Внутренние системы | DE | + |

#### Результат этапа
- Сформирована единая витрина `<call_id, transcript_text, checklist_type, qa_scores[11]>`
- Подтверждена применимость транскриптов для LLM-инференса без дополнительной очистки
- Зафиксированы риски: дисбаланс классов, нестабильность критерия «Холд»

---

### Этап 2. Бейзлайн-оценка (Zero / Few-shot LLM)

#### Цель этапа
Проверить применимость LLM-подхода для автоматической оценки качества звонков и оценить достижимый уровень согласованности с QA без обучения модели.

#### Формирование выборки
- Объём: 181 звонок  
- Период: случайная выборка за 2 недели  
- Разделение: единая тестовая выборка  
- Стратификация: не применяется  

#### Техника решения (бейзлайн)
- Модель: GPT-OSS 20B (vLLM, self-hosted)
- Один prompt на звонок, оценивающий все 11 критериев
- Формат ответа: строго JSON
- Выход: оценки + краткие пояснения по каждому критерию

#### Метрики качества
- Cohen’s Kappa:
  - по каждому критерию
  - агрегированная по всем критериям
- Минимально приемлемый порог: Kappa ≥ 0.7 (агрегированно)

#### Результат этапа
- Подтверждение применимости LLM
- Выявление слабых критериев (ожидаемо — «Холд»)
- Решение о необходимости fine-tuning

#### Риски
- Дисбаланс классов
- Ошибки разметки спикеров (Клиент / Оператор)

#### Бизнес-проверка
- Side-by-side сравнение оценок модели и QA

---

### Этап 3. Основная MVP-модель (Few-shot + Fine-tuning)

#### Цель этапа
Достижение устойчивой согласованности с QA, достаточной для пилота (≥10% покрытия звонков).

#### Формирование выборки
- Объём: < 5k звонков
- Разделение: train / test
- Временная валидация: не применяется
- Балансировка классов: не применяется

#### Техника решения
- Instruction-tuning + LoRA
- Одна модель на все критерии
- Генерация оценок и пояснений в одном ответе

#### Метрики качества
- Основная метрика: Cohen’s Kappa
- Целевое значение: Kappa ≥ 0.8 (агрегированно)
- Критичная ошибка: заниженная оценка

#### Результат этапа
- Стабильная модель оценки качества звонков
- Воспроизводимые результаты по критериям

#### Риски
- Нестабильность критерия «Холд»
- Ошибки разметки ролей в транскриптах

#### Бизнес-проверка
- Side-by-side сравнение модельных и QA-оценок

---

### Этап 4. Подготовка и итерации инференса

#### Инференс
- Режим: batch
- Частота: ежедневно
- Производительность: до 400 звонков в час

#### Версионирование
- Версии модели
- LoRA-веса
- Промпты

#### Результат этапа
- Воспроизводимый batch-пайплайн
- Готовность к пилоту (≥10% покрытия)

## 3. Подготовка пилота

### 3.1. Способ оценки пилота

Пилот проводится в формате контролируемой проверки применимости ML-модели для автоматической оценки качества работы операторов на основе транскриптов звонков.

Основной формат валидации — **Side-by-side разбор расхождений** между модельной оценкой и ручной оценкой QA-специалистов.

Валидация проводится следующим образом:

- модель выполняет batch-оценку части дневных транскриптов
- оценки по каждому критерию формируются в диапазоне `0 / 1 / 2` + краткое объяснение
- данные сопоставляются с QA-разметкой на той же выборке
- выделяются звонки с расхождениями (по любым критериям)
- QA-команда проводит экспертный разбор расхождений
- фиксируются причины расхождений (ошибка модели / допустимое расхождение / спорный случай)

Ответственные роли:

| Роль | Зона ответственности |
|------|----------------------|
| Product Owner | определение бизнес-эффекта и объема покрытия |
| Data Scientist | формирование выборки, подготовка инференса и расчета метрик |
| QA-команда | экспертная проверка расхождений и формирование заключения |

Модель работает в **shadow-режиме** — оценки не используются для управленческих решений и не влияют на KPI операторов на период пилота.

---

### 3.2. Что считаем успешным пилотом

Пилот считается успешным при выполнении следующих условий:

**Бизнес-результаты**

- рост покрытия звонков автоматической оценкой  
  — не менее **10–20% суточных транскриптов**
- сокращение доли звонков, требующих полной ручной проверки QA

**Критерий качества модели**

- агрегированное значение  
  **Weighted Cohen’s Kappa > 0.8**  
  между модельной и QA-разметкой

**Процессная устойчивость**

- расхождения анализируются только на выделенной подвыборке
- критерий «критичных заниженных оценок» отсутствует или минимален
- модель демонстрирует стабильность оценок по большинству критериев

**Валидация QA**

- QA-команда подтверждает,
  что для большинства расхождений:
  - либо оценка модели допустима,
  - либо объяснение модели помогает ускорить проверку

Отдельно фиксируется риск:

- **смещение оценок по отдельным критериям**  
  (например, для специфических сценариев разговоров)

При наличии признаков системного смещения по критериям
— пилот считается частично успешным и требуется дообучение / корректировка промптов.

---

### 3.3. Подготовка пилота

#### Объем и режим инференса

- режим выполнения: batch инференс
- частота: ежедневно
- покрытие пилота: **10–20% суточных транскриптов**
- валидации QA подлежат **только звонки с расхождениями**

Инференс выполняется на локальной инфраструктуре:

- **1 × A100**
- **256 GB RAM**
- **32 CPU**

#### Оценка вычислительной нагрузки

Подход к оценке вычислительной сложности:

1) сначала проводится **инференс бейзлайна**
2) измеряется latency и пропускная способность
3) после этого уточняется целевой объем пилота

На текущем этапе замерено:

- производительность — **≈300 звонков / час**
- этого достаточно для пилотного покрытия 10–20%

#### Ограничение по стоимости вычислений

Так как бюджет на вычисления не фиксирован заранее:

- параметры пилота (объем покрытия, частота запусков)
  будут уточняться после серии прогонов бейзлайна
- допускается установка верхнего лимита на количество звонков в сутки,
  проходящих через модель

#### Подготовительные шаги перед запуском пилота

- формирование стабильного batch-пайплайна инференса
- фиксация версии модели / промптов / датасета
- подготовка витрины результатов:
  - модельная оценка
  - QA-оценка
  - объяснение модели
- определение формата отчета для QA
- настройка выгрузки выборки с расхождениями
- согласование регламента разбора кейсов

Результатом этапа подготовки является готовность к ограниченному пилотному покрытию с контролируемой нагрузкой на вычислительные ресурсы и QA-команду.

## 4. Внедрение

### 4.1. Архитектура решения

**Диаграмма (MVP, batch):**


```
[STT/ETL] → [Batch Orchestrator] → [Preprocess]
                                  → [vLLM Scoring Service (OpenAI-compatible)]
                                  → [Postprocess/Validator] → [DB Storage] → [Reporting/BI]
                                                                                   ↘
                                                                                    [QA System]
```

**Пояснения:**
- **Batch Orchestrator** — расписание батчей (ежедневно), контроль объема 10% выборки.
- **Preprocess** — нормализация текста/метаданных, подготовка промпта.
- **vLLM Scoring Service** — self-hosted LLM через OpenAI‑совместимый HTTP API.
- **Postprocess/Validator** — парсинг JSON, нормализация оценок `0/1/2`, контроль схемы.
- **DB Storage** — сохранение результатов для отчетности и витрин.
- **Reporting/BI + QA** — аналитика и side‑by‑side сравнение с разметкой.

### 4.2. Описание инфраструктуры и масштабируемости

- **Инфраструктура:** on‑prem, self‑hosted vLLM.
- **Почему:** требования к периметру и локальному исполнению, отсутствие внешних API.
- **Плюсы:** контроль данных, предсказуемая производительность, отсутствие vendor lock‑in.
- **Минусы:** необходимость поддержки GPU‑инфраструктуры и мониторинга.
- **Масштабирование:** горизонтальное по vLLM‑инстансам и batch‑воркерам, шардирование по списку звонков.
- **Почему выбор лучше альтернатив:** исключает внешние API, соответствует ограничениям безопасности и доступности данных.

### 4.3. Требования к работе системы

- **Режим:** batch, ежедневно.
- **Объем:** ~400 звонков/сутки (≈10%).
- **Производительность:** целевая пропускная способность 300–500 звонков/час.
- **Задержка batch:** окно выполнения до 2 часов.
- **SLA доступности сервисов:** 99.5% (внутренний сервис).
- **Надежность:** ретраи на ошибки LLM, идемпотентная запись результатов, логирование ошибок.

### 4.4. Безопасность системы

- Сервис доступен только в корпоративной сети (on‑prem).
- Контроль доступа по сервисным ключам, ограничения по IP/сети.
- Логи запросов без ПД, мониторинг ошибок и throughput.

### 4.5. Безопасность данных

- Входные данные обезличены (ПД удалены на уровне STT).
- Обработка только внутри периметра компании.
- Требования GDPR/152‑ФЗ не нарушаются (ПД отсутствуют).

### 4.6. Издержки

- Основные издержки: GPU‑инференс vLLM + хранение результатов в БД.
- Точные цифры бюджета не раскрываются.

### 4.7. Integration points

- **LLM сервис:** OpenAI‑совместимый HTTP API (chat completions).
- **Хранилище:** запись результатов в существующую БД (таблица результатов модели).
- **QA система:** чтение результатов из БД для сравнения и разборов.
- **Витрина/BI:** выгрузка агрегатов и отчетов из БД.

### 4.8. Риски

- Дрейф данных и изменение качества транскриптов.
- Несогласованность оценок модели и QA на отдельных сценариях.
- Нестабильность критерия «Холд».
- Деградация при обновлении STT‑модели без переоценки промптов.

### 4.9. Нагрузочное тестирование

**Оценочные результаты (на 1× NVIDIA A100, batch‑режим):**
- Средняя скорость: 6–8 запросов/мин (≈360–480 звонков/час) при обработке ~2000 символов на звонок.
- Средняя задержка на звонок: 7–10 сек.
- Пиковая нагрузка: до 10 запросов/мин (≈600 звонков/час) при коротких транскриптах.
- Одновременные запросы: 2–4.
