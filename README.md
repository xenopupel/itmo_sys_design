# Оценка качества операторов по текстовым диалогам с помощью LLM

Этот проект направлен на автоматическую оценку качества работы операторов технической поддержки на основе текстовых транскрипций их разговоров с пользователями.  
Вместо ручной разметки и субъективных метрик используется LLM, которая анализирует диалог и генерирует итоговый скор по заранее определённым параметрам (например: тон, компетентность, ясность ответа, соблюдение скриптов и т.п.).

---

## Основные цели проекта

- Автоматизировать оценку эффективности операторов на основе текстовых данных.
- Снизить нагрузку на ручную проверку качества.
- Повысить объективность и единообразие оценки.
- Исследовать применимость LLM для анализа разговоров customer support.

---

## Стек

- **Python**
- **LLM**
- **Poetry** — управление зависимостями
- **Ruff + Black + Mypy** — линтинг/форматирование/типизация

---

## Запуск

### Создание окружения

```bash
poetry install
```

```bash
poetry shell
```

### Переменные окружения

- `OPENAI_API_BASE` — URL OpenAI-совместимого сервиса
- `OPENAI_API_KEY` — API-ключ
- `CRITERIA_PATH` — путь к YAML с критериями

### Сервис (FastAPI)

```bash
uvicorn app:app --host 0.0.0.0 --port 8000
```

Пример запроса:

```json
{
  "calls": [
    {
      "call_id": "call_1",
      "transcript_text": "Текст транскрипта...",
      "checklist_type": "support"
    }
  ]
}
```
